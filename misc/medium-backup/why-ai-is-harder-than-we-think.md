## Why AI is harder than we think?

## And how its challenges relate to other domains

![Dating a robot isn’t easy either](https://cdn-images-1.medium.com/max/2560/1*xhmbKa3fq6gyi5Yr6waDxA.jpeg)

[The original paper can be found here.](https://arxiv.org/pdf/2104.12871.pdf)

In Melanie Mitchel’s paper “Why AI is Harder Than We Think,” the problem that AI field can’t live up to its promises is attributed to the fact that there exist fundamental fallacies in how AI scientists approach the subject.

The fallacies that Melanie Mitchel attributes to research in AI are the following:

- Narrow intelligence is on a continuum with general intelligence

- Easy things are easy and hard things are hard

- The lure of wishful mnemonics

- Intelligence is all in the brain

I agree with the author regarding the fallacies.

I agree that there is a misconception where people put **narrow intelligence on a continuum with general intelligence** as it can even be seen in the fields outside of AI.

Cognitive tests, academic standardized tests, or even the interview questions many IT firms use all fall into the same trap. For the latter, the rote memorization of algorithms and being able to reproduce them on the whiteboard often have very little to do with the actual job and don’t guarantee good performance either. In a sense, passing these specific tests is a narrow skill that isn’t always transferable to other domains. This bias is definitely a big problem and a fallacy that the field of AI, as well as many other fields, is facing.

I think the origin of this fallacy lies in how we humans assign value to things. I will go into more about this in the next fallacy.

I also agree that there is a misconception where people consider **“easy” things easy and “hard” things hard.**

I think the origin of this fallacy lies in that we often get desensitized to things that we encounter often. Because it is so common for us to be able to talk, walk, think, and so on, we place little value on it as it is considered replaceable. Being excellent in a narrow skill, however, is not as common and not as replaceable, and therefore considered by us as having more value. However, what’s common in humans is the opposite in machines. In this case, what seems to us to be of little value turns out to be a real engineering marvel. I believe this paradox has its roots in our mind’s “value assignment system” and the shortcuts it takes.

I consider this and the previous fallacy to be of the same origin and believe that this fallacy is really a continuation of the previous one.

Regarding the misconception where people apply **anthropocentric labels to AI concepts and phenomena**, I agree that it might lead to erroneous conclusions, but I think it is the least fallacious bias compared to the rest of the biases.

I think that the concepts that revolve around simulation as examined by thinkers like Alan Turing with his famous test, Baudrillard with the concept of simulacra, as well as pop-culture creators with movies like Blade Runner and the Matrix, all hint at the fact that even though there is a substantial difference between fake and real, for the vast majority of us it does the trick and can become a reality.

This fallacy isn’t in the way of having systems that are intelligent enough to trick people, but it is in the way of the objective understanding of what intelligence is.

Therefore, I think it is really a matter of how fine-grained we tune the artificial intelligence systems until they become “good enough” and just seem intelligent to us, to be able to say: “alright, it’s intelligent” because humans and their perception are being the main criterion here, as opposed to the real understanding of intelligence.

Therefore, to me, this bias doesn’t really seem to be in the way of progress as much as other biases.

Regarding the misconception where people consider **brain and intelligence to be essentially the same thing**, I agree that it might lead us away from a fundamental understanding of the problem, however, just like with the previous fallacy, I don’t think it’s in the way of achieving the simulacra effect. Which, I believe is what most practitioners of AI are after.

I believe that in the field of evolutionary computation there exist fallacies that are similar to the ones discussed in the paper.

Because it is important to remember that our minds are intertwined with emotions that often affect how we place value on certain aspects of reasoning and because science is a human activity, albeit methodologically quite complex, it will always carry the mark of emotional reasoning, which is not necessarily bad in my opinion, but I will not go in detail as to why.

The field of evolutionary computation is no exception here. I think the core fallacy at play in science, including this field, is religious faith in progress and certain religion-isation of scientific concepts, or, in other words, wishful thinking.

Science is done by people. These people have certain opinions. It is not unheard of when scientists believe in singularity or rely on mathematical abstractions claiming that the economy can grow forever, or believe that theory of evolution can explain all the intricacies of biological phenomena.

Glorification of evolution is a key example of wishful thinking. Even though we have some understanding of the process that lies behind the adaptability of living organisms, there remain tons of mysteries behind how life was able to get to the level it got. Evolving to the stage of extremely robust and intelligent multicellular organisms.

An algorithm of evolution is more or less just a heuristic function for combinatorial search, and those who glorify evolution say, well just give it millions of years to evolve. As computer science students, we are aware that simply throwing more time at an algorithm does not give you a guarantee it will converge at the optimal solution, or even a “good” solution.

This heuristic mechanism of evolution by selection is powerful, but it is a tool in a shed.

The fact that crafting a selection mechanism when using genetic algorithms is a very sophisticated task is quite humbling and raises many questions as to what mechanisms contributed to the design of the evolutionary selection in nature to get the marvelous results that we call life.

To finalize, I agree that AI is harder than we think because our thinking about it is based on certain fallacies, however, I do believe that even with these fallacies the imitation of human-level intelligence that would be indistinguishable by humans from human intelligence is possible and is just the matter of time. However, I am not so sure we will be getting closer to understanding the true nature of intelligence as we achieve these simulations.
